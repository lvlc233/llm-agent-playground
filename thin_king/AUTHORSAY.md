# 作者说
害,这里就可以随便写了(╯°Д°)╯︵ ┻━┻

这个项目核心其实只有一点: 使用工具信息的增强 LLM 的推理,并验证是否具有可行性.

当然,在我这里,工具信息仍然属于提示词或者说在过去被我们意指为提示词的那个东西,简而言之,这个项目真正想要探索的是 LLM 自身关于 '思考' 能力的边界与可能.

补充: 作者如果没有补充论文或者观点连接,要么就是找不到了,要么就是懒(xixi),后续会把相关的论文或者观点连接补充上的.

这个项目有两个十分重要的观点和论文(具体忘记了连接是什么)
1. 将思考外移到工具调用中: 似乎是Anthropic的文?忘记了，在MCP中，也存在一个Server叫 `sequentialthinking` 也是将思考外移到工具调用中。不过不清楚这个Server的思想逻辑，只是为我的想法奠定了一些可实现的价值依据。 
2. 模型本身具有不同的思考的能力: 这是我的观点，或者说假设，即 `模型内容存在许多不同的思考模式,甚至人类不存在的思考模式,并且这些模式可以通过 引导 来 实现`，这个想法没有直接的论文可以作证，在佐证和支持的论文与观点中，有一篇论文相对比较重要,也是开启这个项目的主要原因,大概的意思就是说: `RL其实没有办法为 LLM 提供更多的思考能力,而只是拔高了这些思考输出的表达概率,而对于非思考模型,使用 模板 (其实就是提示词) 就可以让 LLM 进行同 RL训练后的思考输出。` 当然还有许多相关的论文,这里暂时不表了。总之这些论文和观点为实现 `基于 Context 驱动的 LLM 思考能力增强`奠定了实现依据基础。

# 一些心路
这个项目开始于2025年10月1号也就是国庆前后到2025年10月8号国庆的思考的一部分，当时只是有些想法当时不知道应该如何实现，因此采取了最简单的方式即 `simple ReAct`(就是最原始的ReAct不用多想)的架构实现。

尽管我写的是xx版本,但请不要误会,更加准确的描述是不同角度是实现方式,一般来说实现的复杂性会随着版本的增加而增加,但并不代表高版本就比低版本好,也并不是严格意义上的升级,实际上可以理解为关于某个阶段下,我对于实现 '思考' 能力增强的不同想法。每个版本都旨在解决一部分可能的问题,所以实际上,可以将不同的版本的思考组合在一起。

